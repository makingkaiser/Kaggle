{"metadata":{"jupytext":{"split_at_heading":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a simple example of a classifier model. i'll briefly explain some parts of the code, but the conceptual guide, as well as relevant snippets of the code, can be found in my notes *here*(reminder to link to chapter 2). \n\nOur model here is designed to classify cat breeds!","metadata":{}},{"cell_type":"markdown","source":"We first do all our initial setup for fastai:","metadata":{}},{"cell_type":"code","source":"!pip install fastbook","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:10.116087Z","iopub.execute_input":"2024-05-17T09:10:10.117040Z","iopub.status.idle":"2024-05-17T09:10:31.161381Z","shell.execute_reply.started":"2024-05-17T09:10:10.117003Z","shell.execute_reply":"2024-05-17T09:10:31.160145Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hide\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:31.163547Z","iopub.execute_input":"2024-05-17T09:10:31.163960Z","iopub.status.idle":"2024-05-17T09:10:44.359555Z","shell.execute_reply.started":"2024-05-17T09:10:31.163925Z","shell.execute_reply":"2024-05-17T09:10:44.358351Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hide\nimport os\nfrom fastbook import *\nfrom fastai.vision.widgets import *","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:44.361008Z","iopub.execute_input":"2024-05-17T09:10:44.361378Z","iopub.status.idle":"2024-05-17T09:10:44.372466Z","shell.execute_reply.started":"2024-05-17T09:10:44.361341Z","shell.execute_reply":"2024-05-17T09:10:44.370912Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And then we grab our first category of images. in this case, siamese cats.","metadata":{}},{"cell_type":"code","source":"results = search_images_ddg('siamese cats')\nims = results.attrgot('contentUrl')\nlen(ims)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:44.375660Z","iopub.execute_input":"2024-05-17T09:10:44.376861Z","iopub.status.idle":"2024-05-17T09:10:49.042831Z","shell.execute_reply.started":"2024-05-17T09:10:44.376811Z","shell.execute_reply":"2024-05-17T09:10:49.041481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at one of our cats here: ","metadata":{}},{"cell_type":"code","source":"#hide\nims = ['https://images.wagwalkingweb.com/media/daily_wag/blog_articles/hero/1678934108.5188236/everything-you-need-to-know-about-siamese-cats.png']\n","metadata":{"hide_input":true,"execution":{"iopub.status.busy":"2024-05-17T09:10:49.045174Z","iopub.execute_input":"2024-05-17T09:10:49.045812Z","iopub.status.idle":"2024-05-17T09:10:49.051148Z","shell.execute_reply.started":"2024-05-17T09:10:49.045746Z","shell.execute_reply":"2024-05-17T09:10:49.049876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dest = 'images/siamese.jpg'\ndownload_url(ims[0], dest)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:49.052985Z","iopub.execute_input":"2024-05-17T09:10:49.054216Z","iopub.status.idle":"2024-05-17T09:10:49.178735Z","shell.execute_reply.started":"2024-05-17T09:10:49.054178Z","shell.execute_reply":"2024-05-17T09:10:49.177319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = Image.open(dest)\nim.to_thumb(128,128)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:49.180638Z","iopub.execute_input":"2024-05-17T09:10:49.181125Z","iopub.status.idle":"2024-05-17T09:10:49.316068Z","shell.execute_reply.started":"2024-05-17T09:10:49.181084Z","shell.execute_reply":"2024-05-17T09:10:49.314466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This seems to have worked nicely, so let's use fastai's `download_images` to download all the URLs for each of our search terms. We'll put each in a separate folder:","metadata":{}},{"cell_type":"code","source":"#bear_types = 'grizzly','black','teddy'\ncat_types = 'siamese', 'tabby', 'maine coon'\n\n#path = Path('bears')\npath = Path('cats')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:49.318695Z","iopub.execute_input":"2024-05-17T09:10:49.319218Z","iopub.status.idle":"2024-05-17T09:10:49.326390Z","shell.execute_reply.started":"2024-05-17T09:10:49.319173Z","shell.execute_reply":"2024-05-17T09:10:49.324897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install duckduckgo_search\nfrom duckduckgo_search import DDGS\nimport os\nos.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\nfrom fastcore.all import *\n\nddgs = DDGS()\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    # return L(ddg_images(term, max_results=max_images)).itemgot('image')\n    return L(ddgs.images(keywords=term, max_results=max_images)).itemgot('image')\n\nif not path.exists():\n    path.mkdir()\n    print(\"made path\")\nfor o in cat_types:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents = True)\n    results = search_images_ddg(f'{o} cat')\n    download_images(dest, urls=search_images(f'{o} cat'))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:10:49.328015Z","iopub.execute_input":"2024-05-17T09:10:49.328586Z","iopub.status.idle":"2024-05-17T09:11:26.595571Z","shell.execute_reply.started":"2024-05-17T09:10:49.328543Z","shell.execute_reply":"2024-05-17T09:11:26.593942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our folder has image files, as we'd expect:","metadata":{}},{"cell_type":"code","source":"fns = get_image_files(path)\nfns","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:26.600747Z","iopub.execute_input":"2024-05-17T09:11:26.602010Z","iopub.status.idle":"2024-05-17T09:11:26.612611Z","shell.execute_reply.started":"2024-05-17T09:11:26.601964Z","shell.execute_reply":"2024-05-17T09:11:26.611655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Often when we download files from the internet, there are a few that are corrupt. Let's check:","metadata":{}},{"cell_type":"code","source":"failed = verify_images(fns)\nfailed","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:26.614036Z","iopub.execute_input":"2024-05-17T09:11:26.614607Z","iopub.status.idle":"2024-05-17T09:11:27.752447Z","shell.execute_reply.started":"2024-05-17T09:11:26.614573Z","shell.execute_reply":"2024-05-17T09:11:27.750991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To remove all the failed images, you can use `unlink` on each of them. Note that, like most fastai functions that return a collection, `verify_images` returns an object of type `L`, which includes the `map` method. This calls the passed function on each element of the collection:","metadata":{}},{"cell_type":"code","source":"failed.map(Path.unlink);","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:27.755197Z","iopub.execute_input":"2024-05-17T09:11:27.755594Z","iopub.status.idle":"2024-05-17T09:11:27.762434Z","shell.execute_reply.started":"2024-05-17T09:11:27.755555Z","shell.execute_reply":"2024-05-17T09:11:27.761062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have downloaded some data, we need to assemble it in a format suitable for model training. Usually, these are called`DataLoaders`.","metadata":{}},{"cell_type":"markdown","source":"## From Data to DataLoaders","metadata":{}},{"cell_type":"markdown","source":"The dataloaders class just stores multiple dataloader objects,usually`train` and `valid` sets. \n\n```python\nclass DataLoaders(GetAttr):\n    def __init__(self, *loaders): self.loaders = loaders\n    def __getitem__(self, i): return self.loaders[i]\n    train,valid = add_props(lambda i,self: self[i])\n```","metadata":{}},{"cell_type":"markdown","source":"\nTo turn downloaded data into a `DataLoaders` object we need at least four things:\n\n- What kinds of data we are working with\n- How to get the list of items\n- How to label these items\n- How to create the validation set\n\nThere are a number of default methods according to common data/application pipelines, but a `Datablock` gives us more control in our construction of a `DataLoaders` object.","metadata":{}},{"cell_type":"code","source":"cats = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), #independent, then dependent variable\n    get_items=get_image_files, #takes a path, recursivley returns list of images\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),#common split of data\n    get_y=parent_label,#basically just gets folder name\n    item_tfms=Resize(128)) #standardizing dims of images ","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:27.764380Z","iopub.execute_input":"2024-05-17T09:11:27.764754Z","iopub.status.idle":"2024-05-17T09:11:27.781430Z","shell.execute_reply.started":"2024-05-17T09:11:27.764723Z","shell.execute_reply":"2024-05-17T09:11:27.780064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThis command has given us a `DataBlock` object. This is like a *template* for creating a `DataLoaders`. We still need to tell fastai the actual source of our data—in this case, the path where the images can be found:","metadata":{}},{"cell_type":"code","source":"dls = cats.dataloaders(path)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:27.782742Z","iopub.execute_input":"2024-05-17T09:11:27.783315Z","iopub.status.idle":"2024-05-17T09:11:27.949190Z","shell.execute_reply.started":"2024-05-17T09:11:27.783283Z","shell.execute_reply":"2024-05-17T09:11:27.948118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A `DataLoaders` includes validation and training `DataLoader`s. `DataLoader` is a class that provides batches of a few items at a time to the GPU. When you loop through a `DataLoader` fastai will give  64 (by default) items at a time, all stacked up into a single tensor. We can take a look at a few of those items by calling the `show_batch` method on a `DataLoader`:","metadata":{}},{"cell_type":"code","source":"dls.valid.show_batch(max_n=6, nrows=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:27.950599Z","iopub.execute_input":"2024-05-17T09:11:27.951591Z","iopub.status.idle":"2024-05-17T09:11:30.661535Z","shell.execute_reply.started":"2024-05-17T09:11:27.951554Z","shell.execute_reply":"2024-05-17T09:11:30.660369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By default `Resize` *crops* the images to fit a square shape of the size requested, using the full width or height. This can result in losing some important details. Alternatively, you can ask fastai to pad the images with zeros (black), or squish/stretch them:","metadata":{}},{"cell_type":"code","source":"cats = cats.new(item_tfms=Resize(128, ResizeMethod.Squish))\ndls = cats.dataloaders(path)\ndls.valid.show_batch(max_n=6, nrows=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:30.662814Z","iopub.execute_input":"2024-05-17T09:11:30.663213Z","iopub.status.idle":"2024-05-17T09:11:33.488386Z","shell.execute_reply.started":"2024-05-17T09:11:30.663178Z","shell.execute_reply":"2024-05-17T09:11:33.487011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cats= cats.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeros'))\ndls = cats.dataloaders(path)\ndls.valid.show_batch(max_n=6, nrows=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:33.490099Z","iopub.execute_input":"2024-05-17T09:11:33.490861Z","iopub.status.idle":"2024-05-17T09:11:36.119642Z","shell.execute_reply.started":"2024-05-17T09:11:33.490823Z","shell.execute_reply":"2024-05-17T09:11:36.118731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Depending on the specifications of our model, we can replace `Resize` with `RandomResizedCrop`. It can take in a parameter`min_scale`, which determines how much of the image to select at minimum each time:","metadata":{}},{"cell_type":"code","source":"cats = cats.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\ndls = cats.dataloaders(path)\ndls.train.show_batch(max_n=6, nrows=1, unique=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:36.120973Z","iopub.execute_input":"2024-05-17T09:11:36.121462Z","iopub.status.idle":"2024-05-17T09:11:38.071493Z","shell.execute_reply.started":"2024-05-17T09:11:36.121432Z","shell.execute_reply":"2024-05-17T09:11:38.069545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We used `unique=True` to have the same image repeated with different versions of this `RandomResizedCrop` transform. ","metadata":{}},{"cell_type":"markdown","source":"a standard set of augmentations that work well(in general) are provided with the `aug_transforms` function. Because our images are now all the same size, we can apply these augmentations to an entire batch of them using the GPU, which will save a lot of time. To tell fastai we want to use these transforms on a batch, we use the `batch_tfms` parameter (note that we're not using `RandomResizedCrop` in this example, so you can see the differences more clearly; we're also using double the amount of augmentation compared to the default, for the same reason):","metadata":{}},{"cell_type":"code","source":"cats = cats.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\n#mult is multiplier, or the extent of our aug_transforms\ndls = cats.dataloaders(path)\ndls.train.show_batch(max_n=6, nrows=2, unique=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:38.073621Z","iopub.execute_input":"2024-05-17T09:11:38.074322Z","iopub.status.idle":"2024-05-17T09:11:40.599092Z","shell.execute_reply.started":"2024-05-17T09:11:38.074289Z","shell.execute_reply":"2024-05-17T09:11:40.597866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have assembled our data in a format fit for model training, let's actually train our classifier. ","metadata":{}},{"cell_type":"markdown","source":"We can train our model first to identify outliers in our data by looking at the losses. Here, we use both `RandomResizedCrop` and `aug_transforms`. ","metadata":{}},{"cell_type":"code","source":"cats = cats.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\ndls = cats.dataloaders(path)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:11:40.600857Z","iopub.execute_input":"2024-05-17T09:11:40.601369Z","iopub.status.idle":"2024-05-17T09:11:40.668537Z","shell.execute_reply.started":"2024-05-17T09:11:40.601329Z","shell.execute_reply":"2024-05-17T09:11:40.666945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now create our `Learner` and fine-tune it in the usual way:","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:21:49.043034Z","iopub.execute_input":"2024-05-17T09:21:49.043484Z","iopub.status.idle":"2024-05-17T09:26:06.794250Z","shell.execute_reply.started":"2024-05-17T09:21:49.043453Z","shell.execute_reply":"2024-05-17T09:26:06.792747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's see whether the mistakes the model is making are mainly thinking that grizzlies are teddies (that would be bad for safety!), or that grizzlies are black bears, or something else. To visualize this, we can create a *confusion matrix*:","metadata":{}},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:36:36.938645Z","iopub.execute_input":"2024-05-17T09:36:36.939180Z","iopub.status.idle":"2024-05-17T09:36:44.522458Z","shell.execute_reply.started":"2024-05-17T09:36:36.939138Z","shell.execute_reply":"2024-05-17T09:36:44.520158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" we can see that the diagonals are the correct match of predicted to actual. \nThe loss is a number that is higher if the model is incorrect (especially if it's also confident of its incorrect answer), or if it's correct, but not confident of its correct answer. In a couple of chapters we'll learn in depth how loss is calculated and used in the training process. For now, `plot_top_losses` shows us the images with the highest loss in our dataset. As the title of the output says, each image is labeled with four things: prediction, actual (target label), loss, and probability. The *probability* here is the confidence level, from zero to one, that the model has assigned to its prediction:","metadata":{}},{"cell_type":"code","source":"interp.plot_top_losses(3, nrows=3)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T09:42:06.824042Z","iopub.execute_input":"2024-05-17T09:42:06.824600Z","iopub.status.idle":"2024-05-17T09:42:08.132487Z","shell.execute_reply.started":"2024-05-17T09:42:06.824547Z","shell.execute_reply":"2024-05-17T09:42:08.131034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that our very first image kind of looks like a main coon AND a tabby, which is why our model got confused.\n\nBesides that, our model seems to be performing well so far.\n","metadata":{}},{"cell_type":"markdown","source":"We can then save our model(and how we created our `DataLoaders`.)\n\n\n> This method even saves the definition of how to create your `DataLoaders`. This is important, because otherwise you would have to redefine how to transform your data in order to use your model in production. fastai automatically uses your validation set `DataLoader` for inference by default, so your data augmentation will not be applied, which is generally what you want.\n\nWhen you call `export`, fastai will save a file called \"export.pkl\":","metadata":{}},{"cell_type":"code","source":"learn.export()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:04:24.098963Z","iopub.execute_input":"2024-05-17T10:04:24.102486Z","iopub.status.idle":"2024-05-17T10:04:24.276940Z","shell.execute_reply.started":"2024-05-17T10:04:24.102436Z","shell.execute_reply":"2024-05-17T10:04:24.275641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn_inf = load_learner(path/'export.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:04:26.558890Z","iopub.execute_input":"2024-05-17T10:04:26.561159Z","iopub.status.idle":"2024-05-17T10:04:26.612107Z","shell.execute_reply.started":"2024-05-17T10:04:26.561111Z","shell.execute_reply":"2024-05-17T10:04:26.610237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we're doing inference, we're generally just getting predictions for one image at a time. To do this, pass a filename to `predict`:","metadata":{}},{"cell_type":"code","source":"learn_inf.predict('images/siamese.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:04:35.498726Z","iopub.execute_input":"2024-05-17T10:04:35.499558Z","iopub.status.idle":"2024-05-17T10:04:35.665095Z","shell.execute_reply.started":"2024-05-17T10:04:35.499515Z","shell.execute_reply":"2024-05-17T10:04:35.663175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This has returned three things: the predicted category in the same format you originally provided (in this case that's a string), the index of the predicted category, and the probabilities of each category. The last two are based on the order of categories in the *vocab* of the `DataLoaders`; that is, the stored list of all possible categories. At inference time, you can access the `DataLoaders` as an attribute of the `Learner`:","metadata":{}},{"cell_type":"code","source":"learn_inf.dls.vocab","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:05:16.495991Z","iopub.execute_input":"2024-05-17T10:05:16.496393Z","iopub.status.idle":"2024-05-17T10:05:16.503969Z","shell.execute_reply.started":"2024-05-17T10:05:16.496365Z","shell.execute_reply":"2024-05-17T10:05:16.502771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Questionnaire","metadata":{}},{"cell_type":"markdown","source":"1. Provide an example of where the cat classification model might work poorly in production, due to structural or style differences in the training data.\n1. Where do text models currently have a major deficiency?\n1. What are possible negative societal implications of text generation models?\n1. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n1. What kind of tabular data is deep learning particularly good at?\n1. What's a key downside of directly using a deep learning model for recommendation systems?\n1. What are the steps of the Drivetrain Approach?\n1. How do the steps of the Drivetrain Approach map to a recommendation system?\n1. Create an image recognition model using data you curate, and deploy it on the web.\n1. What is `DataLoaders`?\n1. What four things do we need to tell fastai to create `DataLoaders`?\n1. What does the `splitter` parameter to `DataBlock` do?\n1. How do we ensure a random split always gives the same validation set?\n1. What letters are often used to signify the independent and dependent variables?\n1. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?\n1. What is data augmentation? Why is it needed?\n1. What is the difference between `item_tfms` and `batch_tfms`?\n1. What is a confusion matrix?\n1. What does `export` save?\n1. What is it called when we use a model for getting predictions, instead of training?\n1. When might you want to use CPU for deployment? When might GPU be better?\n1. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?\n1. What are three examples of problems that could occur when rolling out a cat identification system in practice?\n1. What is \"out-of-domain data\"?\n1. What is \"domain shift\"?\n1. What are the three steps in the deployment process?","metadata":{}}]}